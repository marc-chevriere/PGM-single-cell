{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marc/mambaforge/envs/PGM/lib/python3.12/site-packages/anndata/utils.py:429: FutureWarning: Importing read_csv from `anndata` is deprecated. Import anndata.io.read_csv instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/marc/mambaforge/envs/PGM/lib/python3.12/site-packages/anndata/utils.py:429: FutureWarning: Importing read_loom from `anndata` is deprecated. Import anndata.io.read_loom instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/marc/mambaforge/envs/PGM/lib/python3.12/site-packages/anndata/utils.py:429: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/marc/mambaforge/envs/PGM/lib/python3.12/site-packages/anndata/utils.py:429: FutureWarning: Importing CSCDataset from `anndata.experimental` is deprecated. Import anndata.abc.CSCDataset instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/marc/mambaforge/envs/PGM/lib/python3.12/site-packages/anndata/utils.py:429: FutureWarning: Importing CSRDataset from `anndata.experimental` is deprecated. Import anndata.abc.CSRDataset instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/marc/mambaforge/envs/PGM/lib/python3.12/site-packages/anndata/utils.py:429: FutureWarning: Importing read_elem from `anndata.experimental` is deprecated. Import anndata.io.read_elem instead.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from anndata import AnnData\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.distributions import Normal, NegativeBinomial, Distribution\n",
    "from torch.distributions import kl_divergence as kl\n",
    "\n",
    "import scvi\n",
    "from scvi.model import SCVI\n",
    "from scvi.data import AnnDataManager\n",
    "from scvi import REGISTRY_KEYS\n",
    "from scvi.module.base import (\n",
    "    BaseModuleClass,\n",
    "    LossOutput,\n",
    "    auto_move_data,\n",
    ")\n",
    "from scvi.model.base import BaseModelClass, UnsupervisedTrainingMixin, VAEMixin\n",
    "from scvi.module import VAE\n",
    "from scvi.data.fields import (\n",
    "    CategoricalJointObsField,\n",
    "    CategoricalObsField,\n",
    "    LayerField,\n",
    "    NumericalJointObsField,\n",
    "    NumericalObsField,\n",
    ")\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger, TensorBoardLogger\n",
    "from collections.abc import Iterator, Sequence\n",
    "import numpy.typing as npt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m File \u001b[35m/Users/marc/Desktop/MVA/cours/\u001b[0m\u001b[95mIntroduction\u001b[0m to graphical                                              \n",
      "         models/projet/PGM-single-cell/data/expression.bin already downloaded                                      \n",
      "\u001b[34mINFO    \u001b[0m Loading Cortex data from \u001b[35m/Users/marc/Desktop/MVA/cours/\u001b[0m\u001b[95mIntroduction\u001b[0m to graphical                          \n",
      "         models/projet/PGM-single-cell/data/expression.bin                                                         \n",
      "\u001b[34mINFO    \u001b[0m Finished loading Cortex data                                                                              \n",
      "(3005, 19972)\n",
      "AnnData object with n_obs × n_vars = 3005 × 19972\n",
      "    obs: 'labels', 'precise_labels', 'cell_type'\n",
      "[2 6 5 4 3 1 0]\n",
      "['1' '2' '3' '4' '5' '6' '7' '8' '9']\n",
      "['interneurons' 'pyramidal SS' 'pyramidal CA1' 'oligodendrocytes'\n",
      " 'microglia' 'endothelial-mural' 'astrocytes_ependymal']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marc/mambaforge/envs/PGM/lib/python3.12/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "# adata = scvi.data.mouse_ob_dataset()\n",
    "# adata = scvi.data.purified_pbmc_dataset()\n",
    "\n",
    "# adata = adata[np.random.choice(adata.shape[0], size=adata.shape[0]//50, replace=False)].copy()\n",
    "# n_genes_to_keep = adata.shape[1] // 4  # Conserver 1/4 des gènes\n",
    "# genes_indices = np.random.choice(adata.shape[1], size=n_genes_to_keep, replace=False)\n",
    "# adata = adata[:, genes_indices].copy()\n",
    "\n",
    "# adata = scvi.data.synthetic_iid()\n",
    "\n",
    "adata = scvi.data.cortex()\n",
    "\n",
    "print(adata.X.shape)\n",
    "print(adata)\n",
    "print(adata.obs[\"labels\"].unique())\n",
    "print(adata.obs[\"precise_labels\"].unique())\n",
    "print(adata.obs[\"cell_type\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_clusters = len(adata.obs[\"precise_labels\"].unique())\n",
    "n_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDecoder(nn.Module):\n",
    "    def __init__(self, n_latent: int, n_output: int, n_hidden: int = 128):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(n_latent, n_hidden)\n",
    "        self.bn1 = nn.BatchNorm1d(n_hidden)\n",
    "        self.fc2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.bn2 = nn.BatchNorm1d(n_hidden)\n",
    "        self.output_mean = nn.Linear(n_hidden, n_output)\n",
    "        self.output_disp = nn.Linear(n_hidden, n_output)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, z: torch.Tensor):\n",
    "        h = self.dropout(torch.relu(self.bn1(self.fc1(z))))\n",
    "        h = self.dropout(torch.relu(self.bn2(self.fc2(h))))\n",
    "        mean = torch.nn.functional.softplus(self.output_mean(h))\n",
    "        disp = torch.nn.functional.softplus(self.output_disp(h))\n",
    "        return mean, disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleEncoder(nn.Module):\n",
    "    def __init__(self, n_input: int, n_latent: int, n_hidden: int = 128):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(n_input, n_hidden)\n",
    "        self.bn1 = nn.BatchNorm1d(n_hidden)\n",
    "        self.fc2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.bn2 = nn.BatchNorm1d(n_hidden)\n",
    "        self.mean_layer = nn.Linear(n_hidden, n_latent)\n",
    "        self.var_layer = nn.Linear(n_hidden, n_latent)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        h = self.dropout(torch.relu(self.fc1(x)))\n",
    "        h = self.dropout(torch.relu(self.fc2(h)))\n",
    "        mean = self.mean_layer(h)\n",
    "        log_var = self.var_layer(h)\n",
    "        return mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVAEModule(BaseModuleClass):\n",
    "    \"\"\"Simple Variational auto-encoder model.\n",
    "\n",
    "    Here we implement a basic version of scVI's underlying VAE [Lopez18]_.\n",
    "    This implementation is for instructional purposes only.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_input\n",
    "        Number of input genes.\n",
    "    n_latent\n",
    "        Dimensionality of the latent space.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input: int,\n",
    "        n_latent: int = 10,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = SimpleEncoder(n_input, n_latent)\n",
    "        self.decoder = SimpleDecoder(n_latent, n_input)\n",
    "\n",
    "\n",
    "    def _get_inference_input(self, tensors: dict[str, torch.Tensor]) -> dict[str, torch.Tensor]:\n",
    "        \"\"\"Parse the dictionary to get appropriate args\"\"\"\n",
    "        # let us fetch the raw counts, and add them to the dictionary\n",
    "        return {\"x\": tensors[REGISTRY_KEYS.X_KEY]}\n",
    "\n",
    "    @auto_move_data\n",
    "    def inference(self, x: torch.Tensor) -> dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        High level inference method.\n",
    "\n",
    "        Runs the inference (encoder) model.\n",
    "        \"\"\"\n",
    "        x_ = torch.log1p(x)\n",
    "        qz_m, qz_v_log = self.encoder(x_)\n",
    "        qz_v = qz_v_log.exp()\n",
    "        z = Normal(qz_m, torch.sqrt(qz_v)).rsample()\n",
    "\n",
    "        return {\"qzm\": qz_m, \"qzv\": qz_v, \"z\": z}\n",
    "\n",
    "    def _get_generative_input(\n",
    "        self, tensors: dict[str, torch.Tensor], inference_outputs: dict[str, torch.Tensor]\n",
    "    ) -> dict[str, torch.Tensor]:\n",
    "        return {\n",
    "            \"z\": inference_outputs[\"z\"],\n",
    "            # \"library\": torch.sum(tensors[REGISTRY_KEYS.X_KEY], dim=1, keepdim=True),\n",
    "        }\n",
    "\n",
    "    @auto_move_data\n",
    "    def generative(self, z: torch.Tensor) -> dict[str, torch.Tensor]:\n",
    "        \"\"\"Runs the generative model.\"\"\"\n",
    "        nb_mean, nb_disp = self.decoder(z)\n",
    "        return {\n",
    "            \"nb_mean\":nb_mean,\n",
    "            \"nb_disp\":nb_disp,\n",
    "        }\n",
    "\n",
    "    def loss(\n",
    "        self,\n",
    "        tensors: dict[str, torch.Tensor],\n",
    "        inference_outputs: dict[str, torch.Tensor],\n",
    "        generative_outputs: dict[str, torch.Tensor],\n",
    "    ) -> LossOutput:\n",
    "        x = tensors[REGISTRY_KEYS.X_KEY]\n",
    "        nb_mean = generative_outputs[\"nb_mean\"]\n",
    "        nb_disp = generative_outputs[\"nb_disp\"]\n",
    "        qz_m = inference_outputs[\"qzm\"]\n",
    "        qz_v = inference_outputs[\"qzv\"]\n",
    "\n",
    "        log_likelihood = NegativeBinomial(total_count=nb_disp, logits=torch.log(nb_mean+1e-4)).log_prob(x).sum(dim=-1)\n",
    "\n",
    "        prior_dist = Normal(torch.zeros_like(qz_m), torch.ones_like(qz_v))\n",
    "        var_post_dist = Normal(qz_m, torch.sqrt(qz_v))\n",
    "        kl_divergence = kl(var_post_dist, prior_dist).sum(dim=-1)\n",
    "\n",
    "        elbo = log_likelihood - kl_divergence\n",
    "        loss = torch.mean(-elbo)\n",
    "        return LossOutput(\n",
    "            loss=loss,\n",
    "            reconstruction_loss=-log_likelihood,\n",
    "            # kl_local=kl_divergence,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVAEModel(VAEMixin, UnsupervisedTrainingMixin, BaseModelClass):\n",
    "    \"\"\"single-cell Variational Inference [Lopez18]_.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        adata: AnnData,\n",
    "        n_latent: int = 10,\n",
    "        **model_kwargs,\n",
    "    ):\n",
    "        super().__init__(adata)\n",
    "\n",
    "        self.module = SimpleVAEModule(\n",
    "            n_input=self.summary_stats[\"n_vars\"],\n",
    "            # n_batch=self.summary_stats[\"n_batch\"],\n",
    "            n_latent=n_latent,\n",
    "            **model_kwargs,\n",
    "        )\n",
    "        self._model_summary_string = (\n",
    "            f\"SCVI Model with the following params: \\nn_latent: {n_latent}\"\n",
    "        )\n",
    "        self.init_params_ = self._get_init_params(locals())\n",
    "\n",
    "    @classmethod\n",
    "    def setup_anndata(\n",
    "        cls,\n",
    "        adata: AnnData,\n",
    "        batch_key: str | None = None,\n",
    "        layer: str | None = None,\n",
    "        **kwargs,\n",
    "    ) -> AnnData | None:\n",
    "        setup_method_args = cls._get_setup_method_args(**locals())\n",
    "        anndata_fields = [\n",
    "            LayerField(REGISTRY_KEYS.X_KEY, layer, is_count_data=True),\n",
    "            CategoricalObsField(REGISTRY_KEYS.BATCH_KEY, batch_key),\n",
    "            # Dummy fields required for VAE class.\n",
    "            CategoricalObsField(REGISTRY_KEYS.LABELS_KEY, None),\n",
    "            NumericalObsField(REGISTRY_KEYS.SIZE_FACTOR_KEY, None, required=False),\n",
    "            CategoricalJointObsField(REGISTRY_KEYS.CAT_COVS_KEY, None),\n",
    "            NumericalJointObsField(REGISTRY_KEYS.CONT_COVS_KEY, None),\n",
    "        ]\n",
    "        adata_manager = AnnDataManager(fields=anndata_fields, setup_method_args=setup_method_args)\n",
    "        adata_manager.register_fields(adata, **kwargs)\n",
    "        cls.register_manager(adata_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">SCVI Model with the following params: \n",
       "n_latent: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
       "Training status: Not Trained\n",
       "</pre>\n"
      ],
      "text/plain": [
       "SCVI Model with the following params: \n",
       "n_latent: \u001b[1;36m10\u001b[0m\n",
       "Training status: Not Trained\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimpleVAEModel.setup_anndata(adata)\n",
    "simple_vae = SimpleVAEModel(adata, n_latent=10)\n",
    "simple_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marc/mambaforge/envs/PGM/lib/python3.12/site-packages/scvi/train/_trainrunner.py:69: UserWarning: `accelerator` has been set to `mps`. Please note that not all PyTorch operations are supported with this backend. Refer to https://github.com/pytorch/pytorch/issues/77764 for more details.\n",
      "  accelerator, lightning_devices, device = parse_device_args(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/marc/mambaforge/envs/PGM/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/marc/mambaforge/envs/PGM/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52573e70a4f4b82bb8a52f308613ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "# logger = WandbLogger(\n",
    "#     project='PGM-single-cell',\n",
    "#     name=\"simple vae\"\n",
    "# )\n",
    "logger = None\n",
    "# logger = TensorBoardLogger(save_dir=\"logs/\", name=\"simple_vae\")\n",
    "\n",
    "simple_vae.train(\n",
    "    max_epochs=3, \n",
    "    logger=logger, \n",
    "    accelerator=\"gpu\",\n",
    "    train_size=0.85,\n",
    "    validation_size=0.1,\n",
    "    early_stopping = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"saved_model_dir\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "model_dir = os.path.join(save_dir, \"simple_vae_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_vae.save(model_dir, save_anndata=True, overwrite=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple_vae = SimpleVAEModel.load(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GM-VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderXtoY(nn.Module):\n",
    "    def __init__(self, n_input: int, n_clusters: int, n_hidden: int = 128):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(n_input, n_hidden),\n",
    "            nn.BatchNorm1d(n_hidden), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),     \n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(n_hidden, n_clusters),\n",
    "            nn.Softmax(dim=-1),       \n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        probs_y = self.mlp(x)\n",
    "        return probs_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderXYtoZ(nn.Module):\n",
    "    def __init__(self, n_input: int, n_clusters: int, n_latent: int, n_hidden: int = 128):\n",
    "        super().__init__()\n",
    "        self.proj_y = nn.Sequential(\n",
    "            nn.Linear(n_clusters, n_hidden),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.BatchNorm1d(n_hidden)\n",
    "        )\n",
    "        self.proj_x = nn.Sequential(\n",
    "            nn.Linear(n_input, n_hidden),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.BatchNorm1d(n_hidden)\n",
    "        )\n",
    "        self.commonlayer = nn.Sequential(\n",
    "            nn.Linear(n_hidden * 2, n_hidden),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "        )\n",
    "        self.output_mean = nn.Linear(n_hidden, n_latent)\n",
    "        self.output_logvar = nn.Linear(n_hidden, n_latent)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor):\n",
    "        proj_x = self.proj_x(x)\n",
    "        proj_y = self.proj_y(y)\n",
    "        xy = torch.cat((proj_x,proj_y), dim=-1)\n",
    "        h = self.commonlayer(xy)\n",
    "        mean_n = self.output_mean(h)\n",
    "        logvar_n = self.output_logvar(h)\n",
    "        return mean_n, logvar_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderYtoZ(nn.Module):\n",
    "    def __init__(self, n_clusters: int, n_latent: int, n_hidden: int = 128):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(n_clusters, n_hidden),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),   \n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1)\n",
    "        )\n",
    "        self.output_mean_n = nn.Linear(n_hidden, n_latent)\n",
    "        self.output_logvar_n = nn.Linear(n_hidden, n_latent) \n",
    "\n",
    "    def forward(self, probs_y: torch.Tensor):\n",
    "        h = self.mlp(probs_y)\n",
    "        mean_n = self.output_mean_n(h)\n",
    "        logvar_n = self.output_logvar_n(h)\n",
    "        return mean_n, logvar_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderZtoX(nn.Module):\n",
    "    def __init__(self, n_output: int, n_latent: int, n_hidden: int = 128):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(n_latent, n_hidden),\n",
    "            nn.BatchNorm1d(n_hidden), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),        \n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "        )     \n",
    "        self.output_mean = nn.Linear(n_hidden, n_output)\n",
    "        self.output_disp = nn.Linear(n_hidden, n_output)\n",
    "\n",
    "    def forward(self, z: torch.Tensor):\n",
    "        h = self.mlp(z)\n",
    "        mean = torch.nn.functional.softplus(self.output_mean(h))  \n",
    "        disp = torch.nn.functional.softplus(self.output_disp(h)) \n",
    "        return mean, disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMVAEModule(BaseModuleClass):\n",
    "    \"\"\"GM Variational auto-encoder model.\n",
    "\n",
    "    Here we implement a basic version of scVI's underlying VAE [Lopez18]_.\n",
    "    This implementation is for instructional purposes only.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_input\n",
    "        Number of input genes.\n",
    "    n_latent\n",
    "        Dimensionality of the latent space.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input: int,\n",
    "        n_clusters: int,\n",
    "        n_latent: int = 10,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoderxtoy = EncoderXtoY(n_input=n_input, n_clusters=n_clusters)\n",
    "        self.encoderxytoz = EncoderXYtoZ(n_clusters=n_clusters, n_input=n_input, n_latent=n_latent)\n",
    "        self.mu_y = nn.Parameter(torch.randn(n_clusters, n_latent))\n",
    "        self.logvar_y = nn.Parameter(torch.zeros(n_clusters, n_latent)) \n",
    "        self.decoderztox = DecoderZtoX(n_output=n_input, n_latent=n_latent)\n",
    "        self.n_clusters = n_clusters\n",
    "        self.n_latent = n_latent\n",
    "\n",
    "\n",
    "    def _get_inference_input(self, tensors: dict[str, torch.Tensor]) -> dict[str, torch.Tensor]:\n",
    "        return {\"x\": tensors[REGISTRY_KEYS.X_KEY]}\n",
    "\n",
    "    @auto_move_data\n",
    "    def inference(self, x: torch.Tensor) -> dict[str, torch.Tensor]:\n",
    "        x_ = torch.log1p(x) \n",
    "        probs_y = self.encoderxtoy(x_)\n",
    "        y_one_hot = torch.eye(self.n_clusters, device=x.device).unsqueeze(0).repeat(x_.size(0), 1, 1)  # (batch_size, n_clusters, n_clusters)\n",
    "        x_expanded = x_.unsqueeze(1).repeat(1, self.n_clusters, 1)  # (batch_size, n_clusters, n_input)\n",
    "        mean_n, logvar_n = self.encoderxytoz(\n",
    "            x=x_expanded.view(-1, x_.size(-1)),  # Fusion des dimensions pour le traitement batch\n",
    "            y=y_one_hot.view(-1, self.n_clusters),  # Idem pour y\n",
    "        )\n",
    "        mean_n = mean_n.view(x_.size(0), self.n_clusters, -1)  # (batch_size, n_clusters, n_latent)\n",
    "        logvar_n = logvar_n.view(x_.size(0), self.n_clusters, -1)  # (batch_size, n_clusters, n_latent)\n",
    "        var_n = logvar_n.exp()\n",
    "        z_normales = Normal(mean_n, torch.sqrt(var_n)).rsample()  # (batch_size, n_clusters, n_latent)\n",
    "\n",
    "        return {\n",
    "            \"qzm\": mean_n,\n",
    "            \"qzv\": var_n,\n",
    "            \"z\": z_normales,\n",
    "            \"probs_y\": probs_y,\n",
    "            \"z_normales\": z_normales\n",
    "        }\n",
    "\n",
    "    def _get_generative_input(\n",
    "        self, tensors: dict[str, torch.Tensor], inference_outputs: dict[str, torch.Tensor]\n",
    "    ) -> dict[str, torch.Tensor]:\n",
    "        return {\n",
    "            \"z_normales\": inference_outputs[\"z_normales\"],\n",
    "        }\n",
    "\n",
    "    @auto_move_data\n",
    "    def generative(self, z_normales: torch.Tensor) -> dict[str, torch.Tensor]:\n",
    "        z_flat = z_normales.view(-1, z_normales.size(-1))  # (batch_size * n_clusters, n_latent)\n",
    "        nb_mean, nb_disp = self.decoderztox(z_flat)  # (batch_size * n_clusters, n_output)\n",
    "        nb_mean = nb_mean.view(z_normales.size(0), z_normales.size(1), -1)\n",
    "        nb_disp = nb_disp.view(z_normales.size(0), z_normales.size(1), -1)\n",
    "\n",
    "        return {\n",
    "            \"nb_mean\": nb_mean,  # (batch_size, n_clusters, n_output)\n",
    "            \"nb_disp\": nb_disp,  # (batch_size, n_clusters, n_output)\n",
    "        }\n",
    "\n",
    "    def loss(\n",
    "        self,\n",
    "        tensors: dict[str, torch.Tensor],\n",
    "        inference_outputs: dict[str, torch.Tensor],\n",
    "        generative_outputs: dict[str, torch.Tensor],\n",
    "    ) -> LossOutput:\n",
    "        x = tensors[REGISTRY_KEYS.X_KEY]\n",
    "        batch_size = x.shape[0]\n",
    "        nb_mean = generative_outputs[\"nb_mean\"] # (batch_size, n_clusters, n_output)\n",
    "        nb_disp = generative_outputs[\"nb_disp\"] # (batch_size, n_clusters, n_output)\n",
    "\n",
    "        qz_m = inference_outputs[\"qzm\"] # (batch_size, n_clusters, n_latent)\n",
    "        qz_v = inference_outputs[\"qzv\"] # (batch_size, n_clusters, n_latent)\n",
    "        z_normales = inference_outputs[\"z\"]  # (batch_size, n_clusters, n_latent)\n",
    "        probs_y = inference_outputs[\"probs_y\"] # (batch_size, n_clusters)\n",
    "\n",
    "        x_expanded = x.unsqueeze(1)\n",
    "        log_likelihood = NegativeBinomial(total_count=nb_disp, logits=torch.log(nb_mean+1e-4)).log_prob(x_expanded).sum(dim=-1) # (batch_size, n_clusters)\n",
    "        mu_y_expanded = self.mu_y.unsqueeze(0).expand(batch_size, -1, -1)  # (n_batch, n_clusters, n_latent)\n",
    "        var_y_expanded = self.logvar_y.unsqueeze(0).expand(batch_size, -1, -1).exp()  # (n_batch, n_clusters, n_latent)\n",
    "        priors_z_y_distributions = Normal(mu_y_expanded, torch.sqrt(var_y_expanded)) # (batch_size, n_clusters)\n",
    "        var_post_dist = Normal(qz_m, torch.sqrt(qz_v)) # (batch_size, n_clusters)\n",
    "        kl_div_1 = kl(var_post_dist, priors_z_y_distributions).sum(dim=-1) # (batch_size, n_clusters)\n",
    "\n",
    "        avg_cat_ll_kl = ((log_likelihood - kl_div_1) * probs_y).sum(dim=1) # (batch_size)\n",
    "\n",
    "        q_y_x = torch.distributions.Categorical(probs_y)\n",
    "        probs_uniform = torch.ones_like(probs_y)/self.n_clusters\n",
    "        unif_pi = torch.distributions.Categorical(probs_uniform)\n",
    "        kl_div_2 = kl(q_y_x, unif_pi).sum(dim=-1) # (batch_size)\n",
    "\n",
    "        elbo = avg_cat_ll_kl - kl_div_2 # (batch_size)\n",
    "        loss = torch.mean(-elbo)\n",
    "        return LossOutput(\n",
    "            loss=loss,\n",
    "            reconstruction_loss=-avg_cat_ll_kl,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMVAEModel(VAEMixin, UnsupervisedTrainingMixin, BaseModelClass):\n",
    "    \"\"\"single-cell Variational Inference [Lopez18]_.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        adata: AnnData,\n",
    "        n_clusters: int,\n",
    "        n_latent: int = 10,\n",
    "        **model_kwargs,\n",
    "    ):\n",
    "        super().__init__(adata)\n",
    "\n",
    "        self.module = GMVAEModule(\n",
    "            n_input=self.summary_stats[\"n_vars\"],\n",
    "            # n_batch=self.summary_stats[\"n_batch\"],\n",
    "            n_clusters=n_clusters,\n",
    "            n_latent=n_latent,\n",
    "            **model_kwargs,\n",
    "        )\n",
    "        self._model_summary_string = (\n",
    "            f\"SCVI Model with the following params: \\nn_latent: {n_latent}\"\n",
    "        )\n",
    "        self.init_params_ = self._get_init_params(locals())\n",
    "\n",
    "\n",
    "    def get_latent_representation(\n",
    "        self,\n",
    "        adata: AnnData | None = None,\n",
    "        indices: Sequence[int] | None = None,\n",
    "        batch_size: int | None = None,\n",
    "        dataloader: Iterator[dict[str, Tensor | None]] = None,\n",
    "    ):\n",
    "\n",
    "        self._check_if_trained(warn=False)\n",
    "        if adata is not None and dataloader is not None:\n",
    "            raise ValueError(\"Only one of `adata` or `dataloader` can be provided.\")\n",
    "\n",
    "        if dataloader is None:\n",
    "            adata = self._validate_anndata(adata)\n",
    "            dataloader = self._make_data_loader(\n",
    "                adata=adata, indices=indices, batch_size=batch_size\n",
    "            )\n",
    "        latent = {}\n",
    "        latent_rep = []\n",
    "        latent_cat = []\n",
    "        for tensors in dataloader:\n",
    "            inference_inputs = self.module._get_inference_input(tensors)\n",
    "            outputs = self.module.inference(**inference_inputs)\n",
    "            qz_m = outputs[\"qzm\"]\n",
    "            probs_y = outputs[\"probs_y\"]\n",
    "            latent_rep += [qz_m.cpu()]\n",
    "            latent_cat += [probs_y.cpu()]\n",
    "        latent[\"latent_rep\"] = torch.cat(latent_rep).detach().numpy()\n",
    "        latent[\"latent_cat\"] = torch.cat(latent_cat).detach().numpy()\n",
    "        return latent\n",
    "\n",
    "    @classmethod\n",
    "    def setup_anndata(\n",
    "        cls,\n",
    "        adata: AnnData,\n",
    "        batch_key: str | None = None,\n",
    "        layer: str | None = None,\n",
    "        **kwargs,\n",
    "    ) -> AnnData | None:\n",
    "        setup_method_args = cls._get_setup_method_args(**locals())\n",
    "        anndata_fields = [\n",
    "            LayerField(REGISTRY_KEYS.X_KEY, layer, is_count_data=True),\n",
    "            CategoricalObsField(REGISTRY_KEYS.BATCH_KEY, batch_key),\n",
    "            # Dummy fields required for VAE class.\n",
    "            CategoricalObsField(REGISTRY_KEYS.LABELS_KEY, None),\n",
    "            NumericalObsField(REGISTRY_KEYS.SIZE_FACTOR_KEY, None, required=False),\n",
    "            CategoricalJointObsField(REGISTRY_KEYS.CAT_COVS_KEY, None),\n",
    "            NumericalJointObsField(REGISTRY_KEYS.CONT_COVS_KEY, None),\n",
    "        ]\n",
    "        adata_manager = AnnDataManager(fields=anndata_fields, setup_method_args=setup_method_args)\n",
    "        adata_manager.register_fields(adata, **kwargs)\n",
    "        cls.register_manager(adata_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">SCVI Model with the following params: \n",
       "n_latent: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
       "Training status: Not Trained\n",
       "</pre>\n"
      ],
      "text/plain": [
       "SCVI Model with the following params: \n",
       "n_latent: \u001b[1;36m10\u001b[0m\n",
       "Training status: Not Trained\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GMVAEModel.setup_anndata(adata)\n",
    "print(n_clusters)\n",
    "gm_vae = GMVAEModel(adata, n_clusters=n_clusters, n_latent=10)\n",
    "gm_vae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marc/mambaforge/envs/PGM/lib/python3.12/site-packages/scvi/train/_trainrunner.py:69: UserWarning: `accelerator` has been set to `mps`. Please note that not all PyTorch operations are supported with this backend. Refer to https://github.com/pytorch/pytorch/issues/77764 for more details.\n",
      "  accelerator, lightning_devices, device = parse_device_args(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/marc/mambaforge/envs/PGM/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/marc/mambaforge/envs/PGM/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07dd17859be84252bd0a6a39408fa701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    }
   ],
   "source": [
    "# logger = WandbLogger(\n",
    "#     project='PGM-single-cell', \n",
    "#     name=\"GM VAE\",\n",
    "#     id=\"gm_vae\",\n",
    "# )\n",
    "# logger = None\n",
    "logger = TensorBoardLogger(save_dir=\"logs/\", name=\"gm_vae\")\n",
    "\n",
    "gm_vae.train(\n",
    "    max_epochs=50, \n",
    "    logger=logger, \n",
    "    accelerator=\"gpu\",\n",
    "    train_size=0.85,\n",
    "    validation_size=0.1,\n",
    "    early_stopping = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5572785\n"
     ]
    }
   ],
   "source": [
    "print(np.max(gm_vae.get_latent_representation(adata)[\"latent_cat\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"saved_model_dir\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "model_dir_gm = os.path.join(save_dir, \"gm_vae_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_vae.save(model_dir_gm, save_anndata=True, overwrite=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gm_vae = GMVAEModel.load(model_dir_gm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE from SCVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/marc/mambaforge/envs/PGM/lib/python3.12/site-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/marc/mambaforge/envs/PGM/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/marc/mambaforge/envs/PGM/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0133127c0774e51810230b3dd8f4864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    }
   ],
   "source": [
    "# logger = WandbLogger(\n",
    "#     project='PGM-single-cell', \n",
    "#     name=\"scvi VAE\",\n",
    "# )\n",
    "# logger = None\n",
    "logger = TensorBoardLogger(save_dir=\"logs/\", name=\"scvi_vae\")\n",
    "\n",
    "scvi.model.SCVI.setup_anndata(adata)\n",
    "\n",
    "# Initialiser le modèle scVI\n",
    "vae = scvi.model.SCVI(adata)\n",
    "\n",
    "# Entraîner le modèle\n",
    "vae.train(\n",
    "    max_epochs=50, \n",
    "    logger=logger, \n",
    "    train_size=0.85,\n",
    "    validation_size=0.1,\n",
    "    early_stopping = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"saved_model_dir\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "model_dir_scvi = os.path.join(save_dir, \"scvi_vae_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.save(model_dir_scvi, save_anndata=True, overwrite=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae = SCVI.load(model_dir_scvi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Scores de Clustering ===\n",
      "\n",
      "VAE de scvi tools :\n",
      "  Adjusted Rand Index (ARI): 0.5614\n",
      "  Normalized Mutual Information (NMI): 0.6957\n",
      "\n",
      "Simple VAE :\n",
      "  Adjusted Rand Index (ARI): 0.5193\n",
      "  Normalized Mutual Information (NMI): 0.6538\n",
      "\n",
      "GM VAE :\n",
      "  Adjusted Rand Index (ARI): 0.2446\n",
      "  Normalized Mutual Information (NMI): 0.3208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Affichage des scores ---\n",
    "print(\"=== Scores de Clustering ===\\n\")\n",
    "\n",
    "# Récupération des vrais labels\n",
    "true_labels = adata.obs['precise_labels']\n",
    "\n",
    "# --- Clustering et évaluation pour le VAE scVI  ---\n",
    "latent_rep_vae = vae.get_latent_representation(adata)\n",
    "kmeans_vae = KMeans(n_clusters=len(set(true_labels)), n_init=200, random_state=42)\n",
    "predicted_labels_vae = kmeans_vae.fit_predict(latent_rep_vae)\n",
    "ari_vae = adjusted_rand_score(true_labels, predicted_labels_vae)\n",
    "nmi_vae = normalized_mutual_info_score(true_labels, predicted_labels_vae)\n",
    "print(\"VAE de scvi tools :\")\n",
    "print(f\"  Adjusted Rand Index (ARI): {ari_vae:.4f}\")\n",
    "print(f\"  Normalized Mutual Information (NMI): {nmi_vae:.4f}\\n\")\n",
    "\n",
    "# --- Clustering et évaluation pour le VAE personnalisé  ---\n",
    "latent_rep_svae = simple_vae.get_latent_representation(adata)\n",
    "kmeans_svae = KMeans(n_clusters=len(set(true_labels)), n_init=200, random_state=42)\n",
    "predicted_labels_svae = kmeans_svae.fit_predict(latent_rep_svae)\n",
    "ari_svae = adjusted_rand_score(true_labels, predicted_labels_svae)\n",
    "nmi_svae = normalized_mutual_info_score(true_labels, predicted_labels_svae)\n",
    "print(\"Simple VAE :\")\n",
    "print(f\"  Adjusted Rand Index (ARI): {ari_svae:.4f}\")\n",
    "print(f\"  Normalized Mutual Information (NMI): {nmi_svae:.4f}\\n\")\n",
    "\n",
    "\n",
    "# --- Clustering et évaluation pour le VAE personnalisé avec GM ---\n",
    "latent_cat_gmvae = gm_vae.get_latent_representation(adata)[\"latent_cat\"]\n",
    "predicted_labels_gmvae = np.argmax(latent_cat_gmvae, axis=-1)\n",
    "ari_gmvae = adjusted_rand_score(true_labels, predicted_labels_gmvae)\n",
    "nmi_gmvae = normalized_mutual_info_score(true_labels, predicted_labels_gmvae)\n",
    "print(\"GM VAE :\")\n",
    "print(f\"  Adjusted Rand Index (ARI): {ari_gmvae:.4f}\")\n",
    "print(f\"  Normalized Mutual Information (NMI): {nmi_gmvae:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PGM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
